{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "Suggested packages:\n",
      "  zip\n",
      "The following NEW packages will be installed:\n",
      "  unzip\n",
      "0 upgraded, 1 newly installed, 0 to remove and 12 not upgraded.\n",
      "Need to get 167 kB of archives.\n",
      "After this operation, 558 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 unzip amd64 6.0-21ubuntu1 [167 kB]\n",
      "Fetched 167 kB in 0s (591 kB/s)\n",
      "debconf: delaying package configuration, since apt-utils is not installed\n",
      "Selecting previously unselected package unzip.\n",
      "(Reading database ... 6778 files and directories currently installed.)\n",
      "Preparing to unpack .../unzip_6.0-21ubuntu1_amd64.deb ...\n",
      "Unpacking unzip (6.0-21ubuntu1) ...\n",
      "Setting up unzip (6.0-21ubuntu1) ...\n"
     ]
    }
   ],
   "source": [
    "!apt-get install unzip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  whole_corpus_eng.zip\n",
      "   creating: whole_corpus_eng/\n",
      "   creating: whole_corpus_eng/extrapolate/\n",
      "  inflating: whole_corpus_eng/.DS_Store  \n",
      "  inflating: __MACOSX/whole_corpus_eng/._.DS_Store  \n",
      "   creating: whole_corpus_eng/interpolate/\n",
      "   creating: whole_corpus_eng/train/\n",
      "  inflating: whole_corpus_eng/extrapolate/algebra__polynomial_roots_big.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._algebra__polynomial_roots_big.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/measurement__conversion.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._measurement__conversion.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/numbers__round_number_big.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._numbers__round_number_big.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/arithmetic__mul_big.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._arithmetic__mul_big.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/numbers__place_value_big.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._numbers__place_value_big.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/comparison__sort_more.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._comparison__sort_more.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/probability__swr_p_sequence_more_samples.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._probability__swr_p_sequence_more_samples.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/comparison__closest_more.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._comparison__closest_more.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/comparison__kth_biggest_more.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._comparison__kth_biggest_more.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/arithmetic__add_sub_multiple_longer.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._arithmetic__add_sub_multiple_longer.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/arithmetic__div_big.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._arithmetic__div_big.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/arithmetic__add_or_sub_big.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._arithmetic__add_or_sub_big.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/arithmetic__mixed_longer.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._arithmetic__mixed_longer.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/probability__swr_p_level_set_more_samples.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._probability__swr_p_level_set_more_samples.txt  \n",
      "  inflating: whole_corpus_eng/extrapolate/arithmetic__mul_div_multiple_longer.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/extrapolate/._arithmetic__mul_div_multiple_longer.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__gcd.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/algebra__linear_2d.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__lcm_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__place_value.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/probability__swr_p_level_set.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__simplify_surd.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/comparison__closest_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/.DS_Store  \n",
      "  inflating: __MACOSX/whole_corpus_eng/interpolate/._.DS_Store  \n",
      "  inflating: whole_corpus_eng/interpolate/polynomials__add.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__is_prime_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/algebra__sequence_next_term.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/measurement__conversion.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/algebra__polynomial_roots.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__div.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__nearest_integer_root.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__round_number_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__lcm.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/probability__swr_p_sequence.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__base_conversion.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/polynomials__evaluate_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/comparison__pair_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/comparison__pair.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/measurement__time.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__div_remainder_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__round_number.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__mixed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/polynomials__expand.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/calculus__differentiate.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/polynomials__evaluate.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__add_or_sub.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__mul.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/polynomials__coefficient_named.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/algebra__polynomial_roots_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__place_value_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__mul_div_multiple.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__add_sub_multiple.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/comparison__sort_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/comparison__closest.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/comparison__kth_biggest.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/comparison__sort.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/algebra__sequence_nth_term.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/arithmetic__add_or_sub_in_base.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/algebra__linear_1d_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/polynomials__collect.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/calculus__differentiate_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/polynomials__compose.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/comparison__kth_biggest_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__is_prime.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__is_factor_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__div_remainder.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/algebra__linear_1d.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/algebra__linear_2d_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__gcd_composed.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/polynomials__simplify_power.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__list_prime_factors.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__is_factor.txt  \n",
      "  inflating: whole_corpus_eng/interpolate/numbers__list_prime_factors_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__gcd.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__gcd.txt  \n",
      "  inflating: whole_corpus_eng/train/algebra__linear_2d.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._algebra__linear_2d.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__lcm_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__lcm_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__place_value.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__place_value.txt  \n",
      "  inflating: whole_corpus_eng/train/probability__swr_p_level_set.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._probability__swr_p_level_set.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__simplify_surd.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__simplify_surd.txt  \n",
      "  inflating: whole_corpus_eng/train/comparison__closest_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._comparison__closest_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/polynomials__add.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._polynomials__add.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__is_prime_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__is_prime_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/algebra__sequence_next_term.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._algebra__sequence_next_term.txt  \n",
      "  inflating: whole_corpus_eng/train/measurement__conversion.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._measurement__conversion.txt  \n",
      "  inflating: whole_corpus_eng/train/algebra__polynomial_roots.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._algebra__polynomial_roots.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__div.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__div.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__nearest_integer_root.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__nearest_integer_root.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__round_number_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__round_number_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__lcm.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__lcm.txt  \n",
      "  inflating: whole_corpus_eng/train/probability__swr_p_sequence.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._probability__swr_p_sequence.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__base_conversion.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__base_conversion.txt  \n",
      "  inflating: whole_corpus_eng/train/polynomials__evaluate_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._polynomials__evaluate_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/comparison__pair_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._comparison__pair_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/comparison__pair.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._comparison__pair.txt  \n",
      "  inflating: whole_corpus_eng/train/measurement__time.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._measurement__time.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__div_remainder_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__div_remainder_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__round_number.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__round_number.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__mixed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__mixed.txt  \n",
      "  inflating: whole_corpus_eng/train/polynomials__expand.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._polynomials__expand.txt  \n",
      "  inflating: whole_corpus_eng/train/calculus__differentiate.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._calculus__differentiate.txt  \n",
      "  inflating: whole_corpus_eng/train/polynomials__evaluate.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._polynomials__evaluate.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__add_or_sub.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__add_or_sub.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__mul.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__mul.txt  \n",
      "  inflating: whole_corpus_eng/train/polynomials__coefficient_named.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._polynomials__coefficient_named.txt  \n",
      "  inflating: whole_corpus_eng/train/algebra__polynomial_roots_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._algebra__polynomial_roots_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__place_value_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__place_value_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__mul_div_multiple.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__mul_div_multiple.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__add_sub_multiple.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__add_sub_multiple.txt  \n",
      "  inflating: whole_corpus_eng/train/comparison__sort_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._comparison__sort_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/comparison__closest.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._comparison__closest.txt  \n",
      "  inflating: whole_corpus_eng/train/comparison__kth_biggest.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._comparison__kth_biggest.txt  \n",
      "  inflating: whole_corpus_eng/train/comparison__sort.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._comparison__sort.txt  \n",
      "  inflating: whole_corpus_eng/train/algebra__sequence_nth_term.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._algebra__sequence_nth_term.txt  \n",
      "  inflating: whole_corpus_eng/train/arithmetic__add_or_sub_in_base.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._arithmetic__add_or_sub_in_base.txt  \n",
      "  inflating: whole_corpus_eng/train/algebra__linear_1d_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._algebra__linear_1d_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/polynomials__collect.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._polynomials__collect.txt  \n",
      "  inflating: whole_corpus_eng/train/calculus__differentiate_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._calculus__differentiate_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/polynomials__compose.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._polynomials__compose.txt  \n",
      "  inflating: whole_corpus_eng/train/comparison__kth_biggest_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._comparison__kth_biggest_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__is_prime.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__is_prime.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__is_factor_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__is_factor_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__div_remainder.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__div_remainder.txt  \n",
      "  inflating: whole_corpus_eng/train/algebra__linear_1d.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._algebra__linear_1d.txt  \n",
      "  inflating: whole_corpus_eng/train/algebra__linear_2d_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._algebra__linear_2d_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__gcd_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__gcd_composed.txt  \n",
      "  inflating: whole_corpus_eng/train/polynomials__simplify_power.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._polynomials__simplify_power.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__list_prime_factors.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__list_prime_factors.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__is_factor.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__is_factor.txt  \n",
      "  inflating: whole_corpus_eng/train/numbers__list_prime_factors_composed.txt  \n",
      "  inflating: __MACOSX/whole_corpus_eng/train/._numbers__list_prime_factors_composed.txt  \n"
     ]
    }
   ],
   "source": [
    "!unzip whole_corpus_eng.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "  Downloading transformers-2.9.0-py3-none-any.whl (635 kB)\n",
      "\u001b[K     |████████████████████████████████| 635 kB 6.2 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Collecting sacremoses\n",
      "  Downloading sacremoses-0.0.43.tar.gz (883 kB)\n",
      "\u001b[K     |████████████████████████████████| 883 kB 20.0 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting sentencepiece\n",
      "  Downloading sentencepiece-0.1.86-cp37-cp37m-manylinux1_x86_64.whl (1.0 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0 MB 22.7 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Collecting regex!=2019.12.17\n",
      "  Downloading regex-2020.5.7-cp37-cp37m-manylinux2010_x86_64.whl (676 kB)\n",
      "\u001b[K     |████████████████████████████████| 676 kB 20.6 MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting tokenizers==0.7.0\n",
      "  Downloading tokenizers-0.7.0-cp37-cp37m-manylinux1_x86_64.whl (5.6 MB)\n",
      "\u001b[K     |████████████████████████████████| 5.6 MB 16.9 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: numpy in /opt/conda/lib/python3.7/site-packages (from transformers) (1.18.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from sacremoses->transformers) (1.14.0)\n",
      "Collecting click\n",
      "  Downloading click-7.1.2-py2.py3-none-any.whl (82 kB)\n",
      "\u001b[K     |████████████████████████████████| 82 kB 1.8 MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting joblib\n",
      "  Downloading joblib-0.14.1-py2.py3-none-any.whl (294 kB)\n",
      "\u001b[K     |████████████████████████████████| 294 kB 25.8 MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for sacremoses: filename=sacremoses-0.0.43-py3-none-any.whl size=893259 sha256=4a34b73b47147ff5ef45d5d5dc4ec001af1b1655c24d361950e57ac52aeb29ac\n",
      "  Stored in directory: /root/.cache/pip/wheels/69/09/d1/bf058f7d6fa0ecba2ce7c66be3b8d012beb4bf61a6e0c101c0\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: regex, click, joblib, sacremoses, sentencepiece, tokenizers, transformers\n",
      "Successfully installed click-7.1.2 joblib-0.14.1 regex-2020.5.7 sacremoses-0.0.43 sentencepiece-0.1.86 tokenizers-0.7.0 transformers-2.9.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "from transformers.modeling_auto import AutoModel\n",
    "import torch\n",
    "from time import time\n",
    "import gc\n",
    "from transformers import BertTokenizer, AutoTokenizer, AutoModelWithLMHead\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf ~/.local/share/Trash/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = ['whole_corpus_eng/train/'+file for file in os.listdir('whole_corpus_eng/train/') if file.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "interpolate_files = ['whole_corpus_eng/interpolate/'+file for file in os.listdir('whole_corpus_eng/interpolate/') if file.endswith('.txt')]\n",
    "extrapolate_files = ['whole_corpus_eng/extrapolate/'+file for file in os.listdir('whole_corpus_eng/extrapolate/') if file.endswith('.txt')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = open('regression.tsv', 'w')\n",
    "\n",
    "for file in train_files:\n",
    "    text = open(file).read().splitlines()\n",
    "    questions, answers = text[::2], text[1::2]\n",
    "    qa = [(q, a) for q, a in zip(questions, answers) if a.isdigit()]\n",
    "    np.random.shuffle(qa)\n",
    "    \n",
    "    for q, a in qa:\n",
    "        data_train.write('\\t'.join([q, a]) + '\\n')\n",
    "data_train.close()\n",
    "\n",
    "random_train = open('random_regression.tsv', 'w')\n",
    "corpus = [line for line in open('regression.tsv')]\n",
    "np.random.shuffle(corpus)\n",
    "for c in corpus:\n",
    "    random_train.write(c)\n",
    "random_train.close()\n",
    "\n",
    "data_interpolate = open('inter_regression.tsv', 'w')\n",
    "\n",
    "for file in interpolate_files:\n",
    "    text = open(file).read().splitlines()\n",
    "    questions, answers = text[::2], text[1::2]\n",
    "    for q, a in zip(questions, answers):\n",
    "        if a.isdigit():\n",
    "            data_interpolate.write('\\t'.join([q, a]) + '\\n')\n",
    "\n",
    "data_interpolate.close()\n",
    "\n",
    "data_extra = open('extra_regression.tsv', 'w')\n",
    "\n",
    "for file in extrapolate_files:\n",
    "    text = open(file).read().splitlines()\n",
    "    questions, answers = text[::2], text[1::2]\n",
    "    for q, a in zip(questions, answers):\n",
    "        if a.isdigit():\n",
    "            data_extra.write('\\t'.join([q, a]) + '\\n')\n",
    "\n",
    "data_extra.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Rubert\n",
    "# tokenizer = AutoTokenizer.from_pretrained(\"DeepPavlov/rubert-base-cased\")\n",
    "# model_bert = AutoModel.from_pretrained(\"DeepPavlov/rubert-base-cased\").to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Eng Bert\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
    "model_bert = AutoModel.from_pretrained('bert-base-cased')\n",
    "# # model = torch.load('en_bert_5epoch').to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Multilingual Bert\n",
    "# tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased')\n",
    "# model_bert = AutoModel.from_pretrained('bert-base-multilingual-cased').to(torch.device('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_batches_choice_torch(file, batch_size=32):\n",
    "    \n",
    "    batch_q = []\n",
    "    batch_a = []\n",
    "    \n",
    "    while True:\n",
    "        for i, line in enumerate(open(file)):\n",
    "            q,a = line.strip('\\n').split('\\t')\n",
    "            batch_q.append(q)\n",
    "            batch_a.append(int(a))\n",
    "\n",
    "            if len(batch_q) == batch_size:\n",
    "                yield (batch_q,\n",
    "                       np.array(batch_a, dtype=np.float32))\n",
    "                batch_q = []\n",
    "                batch_a = []\n",
    "\n",
    "                \n",
    "def gen_batches_choice_val(file, batch_size=32):\n",
    "    batch_q = []\n",
    "    batch_a = []\n",
    "    \n",
    "    for i, line in enumerate(open(file)):\n",
    "\n",
    "        q,a = line.strip('\\n').split('\\t')\n",
    "        batch_q.append(q)\n",
    "        batch_a.append(int(a))\n",
    "\n",
    "        if len(batch_q) == batch_size:\n",
    "            yield (batch_q,\n",
    "                   np.array(batch_a, dtype=np.float32))\n",
    "            batch_q = []\n",
    "            batch_a = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class Model_Reg(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "\n",
    "        super().__init__()          \n",
    "        \n",
    "        self.tokenizer = tokenizer\n",
    "        self.bert = model_bert\n",
    "        self.num_iter = 0\n",
    "        self.fake_epoch = 0\n",
    "        self.fc = nn.Linear(768, 1)\n",
    "        \n",
    "    def forward(self, texts): \n",
    "        texts_ids = [torch.tensor(self.tokenizer.encode(t, add_special_tokens=True)) for t in texts]\n",
    "        texts_ids = torch.nn.utils.rnn.pad_sequence(texts_ids, batch_first=True).to(torch.device('cuda'))\n",
    "        mask = (texts_ids != tokenizer.pad_token_id).long()\n",
    "        hidden, pooler = self.bert(texts_ids, attention_mask=mask)\n",
    "\n",
    "#         num =self.fc(pooler)\n",
    "        num =self.fc(hidden[:, 0])\n",
    "\n",
    "        \n",
    "        self.num_iter += 1\n",
    "        return num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model_Reg()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "#define optimizer and loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "#define metric\n",
    "def accuracy(preds, y):\n",
    "    #round predictions to the closest integer\n",
    "    rounded_preds = preds.round()\n",
    "    \n",
    "    correct = (rounded_preds == y).float() \n",
    "    acc = correct.sum() / len(correct)\n",
    "    return acc\n",
    "    \n",
    "#push to cuda if available\n",
    "model = model.to(device)\n",
    "criterion = criterion.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, batch_size, epoch):\n",
    "    epoch_loss = []\n",
    "    epoch_acc = []\n",
    "\n",
    "    model.train()  \n",
    "\n",
    "    for i, batch in enumerate(iterator):\n",
    "\n",
    "        #resets the gradients after every batch\n",
    "        optimizer.zero_grad()   \n",
    "\n",
    "        #retrieve text and no. of words\n",
    "        texts, labels = batch[0], batch[1]   \n",
    "\n",
    "        #convert to 1D tensor\n",
    "        predictions = model(texts).squeeze()\n",
    "\n",
    "        #compute the loss\n",
    "        loss = criterion(predictions, torch.log1p(torch.Tensor(labels)).to(device))        \n",
    "\n",
    "        #compute the binary accuracy\n",
    "        acc = accuracy(torch.expm1(predictions), torch.Tensor(labels).to(device))   \n",
    "\n",
    "        #backpropage the loss and compute the gradients\n",
    "        loss.backward()       \n",
    "\n",
    "        #update the weights\n",
    "        optimizer.step()      \n",
    "\n",
    "        #loss and accuracy\n",
    "        epoch_loss.append(loss.item())  \n",
    "        epoch_acc.append(acc.item())\n",
    "        \n",
    "        if not ((model.num_iter+1)*batch_size) % 30000:\n",
    "            print(model.fake_epoch)\n",
    "            model.fake_epoch += 1\n",
    "            print(np.mean(epoch_loss), np.mean(epoch_acc))\n",
    "            epoch_loss = []\n",
    "            epoch_acc = []\n",
    "\n",
    "        if ((model.num_iter*batch_size)//3754297) >= epoch:\n",
    "            return (np.mean(epoch_loss), np.mean(epoch_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(model, iterator):\n",
    "\n",
    "#set the model in training phase\n",
    "    model.train(mode=False)  \n",
    "    val_loss = []\n",
    "    val_acc = []\n",
    "    for i, batch in enumerate(iterator):\n",
    "        #retrieve text and no. of words\n",
    "        texts, labels = batch[0], batch[1]   \n",
    "\n",
    "        #convert to 1D tensor\n",
    "        predictions = model(texts).squeeze()  \n",
    "\n",
    "        #compute the loss\n",
    "        loss = criterion(predictions, torch.log1p(torch.Tensor(labels)).to(device))        \n",
    "\n",
    "        #compute the binary accuracy\n",
    "        acc = accuracy(torch.expm1(predictions), torch.Tensor(labels).to(device))\n",
    "\n",
    "        val_loss.append(loss.item())  \n",
    "        val_acc.append(acc.item())  \n",
    "\n",
    "    return (np.mean(val_loss), np.mean(val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "On epoch: 0; Train Loss: 10.592344284057617; Train Accuracy: 0.125\n",
      "On epoch: 0; Inter Loss: 13.918464422303495; Inter Accuracy: 0.03295750216825672\n",
      "On epoch: 0; Extra Loss: 52.60209835153453; Extra Accuracy: 0.029846938775510205\n",
      "Elapsed Time: 48.677154302597046\n",
      "0\n",
      "9.18378685022211 0.03558781869688385\n",
      "1\n",
      "6.2876959176540375 0.04586666666666667\n",
      "2\n",
      "3.800500013868014 0.0558\n"
     ]
    }
   ],
   "source": [
    "from time import time\n",
    "\n",
    "for i in range(0, 21):\n",
    "    start = time()\n",
    "    iterator = gen_batches_choice_torch('random_regression.tsv', 16)\n",
    "    l, a = train(model, iterator, 16, i)\n",
    "    print(f'On epoch: {i}; Train Loss: {l}; Train Accuracy: {a}')\n",
    "    iterator = gen_batches_choice_val('inter_regression.tsv',16)\n",
    "    li, ai = validate(model, iterator)\n",
    "    iterator = gen_batches_choice_val('extra_regression.tsv',16)\n",
    "    le, ae = validate(model, iterator)\n",
    "    print(f'On epoch: {i}; Inter Loss: {li}; Inter Accuracy: {ai}')\n",
    "    print(f'On epoch: {i}; Extra Loss: {le}; Extra Accuracy: {ae}')\n",
    "    print(f'Elapsed Time: {time()-start}')\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_LEN = 0\n",
    "INTER_LEN = 0\n",
    "EXTRA_LEN = 0\n",
    "unique = set()\n",
    "for line in open('random_regression.tsv'):\n",
    "    q,a = line.strip('\\n').split('\\t')\n",
    "    TRAIN_LEN += 1\n",
    "    \n",
    "for line in open('inter_regression.tsv'):\n",
    "    q,a = line.strip('\\n').split('\\t')\n",
    "    INTER_LEN += 1\n",
    "    \n",
    "    \n",
    "for line in open('extra_regression.tsv'):\n",
    "    q,a = line.strip('\\n').split('\\t')\n",
    "    unique.add(a)\n",
    "    EXTRA_LEN += 1\n",
    "    \n",
    "# for line in open('extrapolate.tsv'):\n",
    "#     EXTRA_LEN += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3754297"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18452"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "INTER_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3933"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXTRA_LEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
