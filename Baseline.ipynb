{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression, Ridge\n",
    "from sklearn.tree import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor, RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import re\n",
    "from sklearn.decomposition import TruncatedSVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sum(text):\n",
    "    nums = [int(x) for x in re.findall('\\d+', text)]\n",
    "    if nums:\n",
    "        return float(sum(nums))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def get_product(text):\n",
    "    nums = [int(x) for x in re.findall('\\d+', text)]\n",
    "    if nums:\n",
    "        prod = 1\n",
    "        for num in nums:\n",
    "            prod *= num\n",
    "        return float(prod)\n",
    "    else:\n",
    "        return 0    \n",
    "\n",
    "def get_aminusb(text):\n",
    "    nums = [int(x) for x in re.findall('\\d+', text)]\n",
    "    if len(nums) == 2:\n",
    "        res = float(nums[0] - nums[1])\n",
    "        if res:\n",
    "            return res\n",
    "        else:\n",
    "            return 0.\n",
    "    else:\n",
    "        return 0.\n",
    "    \n",
    "def get_bminusa(text):\n",
    "    nums = [int(x) for x in re.findall('\\d+', text)]\n",
    "    if len(nums) == 2:\n",
    "        res = float(nums[1] - nums[0])\n",
    "        if res:\n",
    "            return res\n",
    "        else:\n",
    "            return 0.\n",
    "    else:\n",
    "        return 0.\n",
    "    \n",
    "def get_adevideb(text):\n",
    "    nums = [int(x) for x in re.findall('\\d+', text)]\n",
    "    if len(nums) == 2:\n",
    "        res = round(nums[0]/nums[1])\n",
    "        if res:\n",
    "            return res\n",
    "        else:\n",
    "            return 0.\n",
    "    else:\n",
    "        return 0.\n",
    "    \n",
    "def get_bdevidea(text):\n",
    "    nums = [int(x) for x in re.findall('\\d+', text)]\n",
    "    if len(nums) == 2:\n",
    "        res = round(nums[1]/nums[0])\n",
    "        if res:\n",
    "            return res\n",
    "        else:\n",
    "            return 0.\n",
    "    else:\n",
    "        return 0.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train = pd.read_csv('augmented_sents_train.csv', sep='\\t', quotechar=\"'\", \n",
    "                         names=['context', 'question', 'answer'])\n",
    "data_test = pd.read_csv('augmented_sents_test.csv', sep='\\t', quotechar=\"'\", \n",
    "                        names=['context', 'question', 'answer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train.dropna(inplace=True)\n",
    "data_test.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>context</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Витя и Катя взяли из пакетика 40 конфетки.</td>\n",
       "      <td>Сколько взяла Катя, если Витя взял 34?</td>\n",
       "      <td>6</td>\n",
       "      <td>Витя и Катя взяли из пакетика 40 конфетки.Сколько взяла Катя, если Витя взял 34?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Витя и Катя взяли из пакетика 49 конфетки.</td>\n",
       "      <td>Сколько взяла Катя, если Витя взял 40?</td>\n",
       "      <td>9</td>\n",
       "      <td>Витя и Катя взяли из пакетика 49 конфетки.Сколько взяла Катя, если Витя взял 40?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Витя и Катя взяли из пакетика 48 конфетки.</td>\n",
       "      <td>Сколько взяла Катя, если Витя взял 33?</td>\n",
       "      <td>15</td>\n",
       "      <td>Витя и Катя взяли из пакетика 48 конфетки.Сколько взяла Катя, если Витя взял 33?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Витя и Катя взяли из пакетика 38 конфетки.</td>\n",
       "      <td>Сколько взяла Катя, если Витя взял 18?</td>\n",
       "      <td>20</td>\n",
       "      <td>Витя и Катя взяли из пакетика 38 конфетки.Сколько взяла Катя, если Витя взял 18?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Витя и Катя взяли из пакетика 28 конфетки.</td>\n",
       "      <td>Сколько взяла Катя, если Витя взял 10?</td>\n",
       "      <td>18</td>\n",
       "      <td>Витя и Катя взяли из пакетика 28 конфетки.Сколько взяла Катя, если Витя взял 10?</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      context  \\\n",
       "0  Витя и Катя взяли из пакетика 40 конфетки.   \n",
       "1  Витя и Катя взяли из пакетика 49 конфетки.   \n",
       "2  Витя и Катя взяли из пакетика 48 конфетки.   \n",
       "3  Витя и Катя взяли из пакетика 38 конфетки.   \n",
       "4  Витя и Катя взяли из пакетика 28 конфетки.   \n",
       "\n",
       "                                 question  answer  \\\n",
       "0  Сколько взяла Катя, если Витя взял 34?       6   \n",
       "1  Сколько взяла Катя, если Витя взял 40?       9   \n",
       "2  Сколько взяла Катя, если Витя взял 33?      15   \n",
       "3  Сколько взяла Катя, если Витя взял 18?      20   \n",
       "4  Сколько взяла Катя, если Витя взял 10?      18   \n",
       "\n",
       "                                                                               text  \n",
       "0  Витя и Катя взяли из пакетика 40 конфетки.Сколько взяла Катя, если Витя взял 34?  \n",
       "1  Витя и Катя взяли из пакетика 49 конфетки.Сколько взяла Катя, если Витя взял 40?  \n",
       "2  Витя и Катя взяли из пакетика 48 конфетки.Сколько взяла Катя, если Витя взял 33?  \n",
       "3  Витя и Катя взяли из пакетика 38 конфетки.Сколько взяла Катя, если Витя взял 18?  \n",
       "4  Витя и Катя взяли из пакетика 28 конфетки.Сколько взяла Катя, если Витя взял 10?  "
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_features=10000)\n",
    "X_context_train = tfidf.fit_transform(data_train['context'])\n",
    "X_question_train = tfidf.transform(data_train['question'])\n",
    "\n",
    "X_context_test = tfidf.transform(data_test['context'])\n",
    "X_question_test = tfidf.transform(data_test['question'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = hstack([X_context_train, X_question_train])\n",
    "X_train = X_train.tocsr()\n",
    "\n",
    "X_test = hstack([X_context_test, X_question_test])\n",
    "X_test = X_test.tocsr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Сумма всех чисел в тексте задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.17899603698811095\n",
      "0.0821917808219178\n"
     ]
    }
   ],
   "source": [
    "sum_all_train = data_train.text.apply(get_sum)\n",
    "sum_all_test = data_test.text.apply(get_sum)\n",
    "print(accuracy_score(y_train, sum_all_train))\n",
    "print(accuracy_score(y_test, sum_all_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Произведение всех чисел в тексте задачи"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10766182298546896\n",
      "0.1113013698630137\n"
     ]
    }
   ],
   "source": [
    "product_all_train = data_train.text.apply(get_product)\n",
    "product_all_test = data_test.text.apply(get_product)\n",
    "print(accuracy_score(y_train, product_all_train))\n",
    "print(accuracy_score(y_test, product_all_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Текстовые признаки + признаки на извлеченных числах"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_train['text'] = data_train['context'] + data_train['question']\n",
    "\n",
    "sums = data_train.text.apply(get_sum).values.reshape(-1, 1)\n",
    "product = data_train.text.apply(get_product).values.reshape(-1, 1)\n",
    "aminusb = data_train.text.apply(get_aminusb).values.reshape(-1, 1)\n",
    "bminusa = data_train.text.apply(get_bminusa).values.reshape(-1, 1)\n",
    "\n",
    "adevideb = data_train.text.apply(get_adevideb).values.reshape(-1, 1)\n",
    "bdevidea = data_train.text.apply(get_bdevidea).values.reshape(-1, 1)\n",
    "\n",
    "sums_context = data_train.context.apply(get_sum).values.reshape(-1, 1)\n",
    "product_context = data_train.context.apply(get_product).values.reshape(-1, 1)\n",
    "aminusb_context = data_train.context.apply(get_aminusb).values.reshape(-1, 1)\n",
    "bminusa_context = data_train.context.apply(get_bminusa).values.reshape(-1, 1)\n",
    "\n",
    "adevideb_context = data_train.context.apply(get_adevideb).values.reshape(-1, 1)\n",
    "bdevidea_context = data_train.context.apply(get_bdevidea).values.reshape(-1, 1)\n",
    "\n",
    "sums_question = data_train.question.apply(get_sum).values.reshape(-1, 1)\n",
    "product_question = data_train.question.apply(get_product).values.reshape(-1, 1)\n",
    "aminusb_question = data_train.question.apply(get_aminusb).values.reshape(-1, 1)\n",
    "bminusa_question = data_train.question.apply(get_bminusa).values.reshape(-1, 1)\n",
    "\n",
    "adevideb_question = data_train.question.apply(get_adevideb).values.reshape(-1, 1)\n",
    "bdevidea_question = data_train.question.apply(get_bdevidea).values.reshape(-1, 1)\n",
    "\n",
    "X_train_with_manual = hstack([X_train, sums, aminusb, bminusa, \n",
    "                        product, adevideb, bdevidea,\n",
    "                       sums_context, aminusb_context, bminusa_context, \n",
    "                        product_context, adevideb_context, bdevidea_context,\n",
    "                       sums_question, aminusb_question, bminusa_question, \n",
    "                        product_question, adevideb_question, bdevidea_question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_test['text'] = data_test['context'] + data_test['question']\n",
    "\n",
    "sums = data_test.text.apply(get_sum).values.reshape(-1, 1)\n",
    "product = data_test.text.apply(get_product).values.reshape(-1, 1)\n",
    "aminusb = data_test.text.apply(get_aminusb).values.reshape(-1, 1)\n",
    "bminusa = data_test.text.apply(get_bminusa).values.reshape(-1, 1)\n",
    "\n",
    "adevideb = data_test.text.apply(get_adevideb).values.reshape(-1, 1)\n",
    "bdevidea = data_test.text.apply(get_bdevidea).values.reshape(-1, 1)\n",
    "\n",
    "sums_context = data_test.context.apply(get_sum).values.reshape(-1, 1)\n",
    "product_context = data_test.context.apply(get_product).values.reshape(-1, 1)\n",
    "aminusb_context = data_test.context.apply(get_aminusb).values.reshape(-1, 1)\n",
    "bminusa_context = data_test.context.apply(get_bminusa).values.reshape(-1, 1)\n",
    "\n",
    "adevideb_context = data_test.context.apply(get_adevideb).values.reshape(-1, 1)\n",
    "bdevidea_context = data_test.context.apply(get_bdevidea).values.reshape(-1, 1)\n",
    "\n",
    "sums_question = data_test.question.apply(get_sum).values.reshape(-1, 1)\n",
    "product_question = data_test.question.apply(get_product).values.reshape(-1, 1)\n",
    "aminusb_question = data_test.question.apply(get_aminusb).values.reshape(-1, 1)\n",
    "bminusa_question = data_test.question.apply(get_bminusa).values.reshape(-1, 1)\n",
    "\n",
    "adevideb_question = data_test.question.apply(get_adevideb).values.reshape(-1, 1)\n",
    "bdevidea_question = data_test.question.apply(get_bdevidea).values.reshape(-1, 1)\n",
    "\n",
    "X_test_with_manual = hstack([X_test, sums, aminusb, bminusa, \n",
    "                        product, adevideb, bdevidea,\n",
    "                       sums_context, aminusb_context, bminusa_context, \n",
    "                        product_context, adevideb_context, bdevidea_context,\n",
    "                       sums_question, aminusb_question, bminusa_question, \n",
    "                        product_question, adevideb_question, bdevidea_question])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_with_manual = X_train_with_manual.tocsr()\n",
    "X_test_with_manual = X_test_with_manual.tocsr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = data_train['answer'].values\n",
    "y_test = data_test['answer'].values\n",
    "\n",
    "y_train_bin = data_train['answer'].apply(lambda x: 1 if x == -1 else 0).values\n",
    "y_test_bin = data_test['answer'].apply(lambda x: 1 if x == -1  else 0).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "svd = TruncatedSVD(30)\n",
    "X_train_with_manual_svd = svd.fit_transform(X_train_with_manual)\n",
    "X_test_with_manual_svd = svd.transform(X_test_with_manual)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Определение некорректных вопросов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegressionCV, RidgeCV\n",
    "from sklearn.tree import DecisionTreeRegressor, DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       433\n",
      "          1       0.96      0.17      0.28       151\n",
      "\n",
      "avg / total       0.82      0.78      0.72       584\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.79      0.80      0.80       433\n",
      "          1       0.41      0.41      0.41       151\n",
      "\n",
      "avg / total       0.70      0.70      0.70       584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_with_manual, y_train_bin)\n",
    "preds = clf.predict(X_test_with_manual)\n",
    "print(classification_report(y_test_bin, preds))\n",
    "\n",
    "clf = LogisticRegressionCV(class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_with_manual_svd, y_train_bin)\n",
    "preds = clf.predict(X_test_with_manual_svd)\n",
    "print(classification_report(y_test_bin, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.82      0.89      0.85       433\n",
      "          1       0.59      0.43      0.50       151\n",
      "\n",
      "avg / total       0.76      0.77      0.76       584\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.89      0.81       433\n",
      "          1       0.29      0.13      0.18       151\n",
      "\n",
      "avg / total       0.63      0.70      0.65       584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=14, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_with_manual, y_train_bin)\n",
    "preds = clf.predict(X_test_with_manual)\n",
    "print(classification_report(y_test_bin, preds))\n",
    "\n",
    "clf = DecisionTreeClassifier(max_depth=14, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_with_manual_svd, y_train_bin)\n",
    "preds = clf.predict(X_test_with_manual_svd)\n",
    "print(classification_report(y_test_bin, preds))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.81      0.99      0.89       433\n",
      "          1       0.91      0.32      0.48       151\n",
      "\n",
      "avg / total       0.83      0.82      0.78       584\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.84      0.80       433\n",
      "          1       0.36      0.26      0.30       151\n",
      "\n",
      "avg / total       0.66      0.69      0.67       584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(max_depth=4, n_estimators=100, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_with_manual, y_train_bin)\n",
    "preds = clf.predict(X_test_with_manual)\n",
    "print(classification_report(y_test_bin, preds))\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=4, n_estimators=100, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_with_manual_svd, y_train_bin)\n",
    "preds = clf.predict(X_test_with_manual_svd)\n",
    "print(classification_report(y_test_bin, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       433\n",
      "          1       0.96      0.15      0.25       151\n",
      "\n",
      "avg / total       0.82      0.78      0.71       584\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.77      1.00      0.87       433\n",
      "          1       0.92      0.15      0.25       151\n",
      "\n",
      "avg / total       0.81      0.78      0.71       584\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=10)\n",
    "clf.fit(X_train_with_manual, y_train_bin)\n",
    "preds_bin = clf.predict(X_test_with_manual)\n",
    "print(classification_report(y_test_bin, preds_bin))\n",
    "\n",
    "clf = KNeighborsClassifier(n_neighbors=10)\n",
    "clf.fit(X_train_with_manual_svd, y_train_bin)\n",
    "preds_bin = clf.predict(X_test_with_manual_svd)\n",
    "print(classification_report(y_test_bin, preds_bin))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Предсказание точного ответа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "# возьмем предсказание лучшей модели определения некорректных вопросов\n",
    "clf = RandomForestClassifier(max_depth=4, n_estimators=100, class_weight='balanced', random_state=42)\n",
    "clf.fit(X_train_with_manual, y_train_bin)\n",
    "preds_bin = clf.predict(X_test_with_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим из обучающей выборки некорректные вопросы\n",
    "only_good_train_X = X_train_with_manual[y_train != -1]\n",
    "only_good_train_y = y_train[y_train != -1]\n",
    "\n",
    "# удалим из обучающей выборки некорректные вопросы\n",
    "only_good_train_X_svd = X_train_with_manual_svd[y_train != -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0839041095890411\n",
      "0.08904109589041095\n"
     ]
    }
   ],
   "source": [
    "# обучим регрессию на корректных вопросах \n",
    "regr = RidgeCV()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(only_good_train_X, )\n",
    "\n",
    "regr.fit(scaler.transform(only_good_train_X), only_good_train_y)\n",
    "# округлим предсказания\n",
    "preds = (regr.predict(scaler.transform(X_test_with_manual))).astype(int)\n",
    "# добавим предсказания некорректных вопросов\n",
    "preds[preds_bin == 1] = -1\n",
    "print(accuracy_score(y_test, preds))\n",
    "\n",
    "\n",
    "# обучим регрессию на корректных вопросах \n",
    "regr = RidgeCV()\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(only_good_train_X_svd, )\n",
    "\n",
    "regr.fit(scaler.transform(only_good_train_X_svd), only_good_train_y)\n",
    "# округлим предсказания\n",
    "preds = (regr.predict(scaler.transform(X_test_with_manual_svd))).astype(int)\n",
    "# добавим предсказания некорректных вопросов\n",
    "preds[preds_bin == 1] = -1\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test.iloc[preds==y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.09075342465753425\n",
      "0.0839041095890411\n"
     ]
    }
   ],
   "source": [
    "# обучим регрессию на корректных вопросах \n",
    "regr = RandomForestRegressor(random_state=42)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(only_good_train_X, )\n",
    "\n",
    "regr.fit(scaler.transform(only_good_train_X), only_good_train_y)\n",
    "# округлим предсказания\n",
    "preds = (regr.predict(scaler.transform(X_test_with_manual))).astype(int)\n",
    "# добавим предсказания некорректных вопросов\n",
    "preds[preds_bin == 1] = -1\n",
    "print(accuracy_score(y_test, preds))\n",
    "\n",
    "\n",
    "# обучим регрессию на корректных вопросах \n",
    "regr = RandomForestRegressor(random_state=42)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(only_good_train_X_svd, )\n",
    "\n",
    "regr.fit(scaler.transform(only_good_train_X_svd), only_good_train_y)\n",
    "# округлим предсказания\n",
    "preds = (regr.predict(scaler.transform(X_test_with_manual_svd))).astype(int)\n",
    "# добавим предсказания некорректных вопросов\n",
    "preds[preds_bin == 1] = -1\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test.iloc[preds==y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.08904109589041095\n",
      "0.0839041095890411\n"
     ]
    }
   ],
   "source": [
    "# обучим регрессию на корректных вопросах \n",
    "regr = KNeighborsRegressor(n_neighbors=3)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(only_good_train_X, )\n",
    "\n",
    "regr.fit(scaler.transform(only_good_train_X), only_good_train_y)\n",
    "# округлим предсказания\n",
    "preds = (regr.predict(scaler.transform(X_test_with_manual))).astype(int)\n",
    "# добавим предсказания некорректных вопросов\n",
    "preds[preds_bin == 1] = -1\n",
    "print(accuracy_score(y_test, preds))\n",
    "\n",
    "\n",
    "# обучим регрессию на корректных вопросах \n",
    "regr = KNeighborsRegressor(n_neighbors=3)\n",
    "scaler = StandardScaler(with_mean=False)\n",
    "scaler.fit(only_good_train_X_svd, )\n",
    "\n",
    "regr.fit(scaler.transform(only_good_train_X_svd), only_good_train_y)\n",
    "# округлим предсказания\n",
    "preds = (regr.predict(scaler.transform(X_test_with_manual_svd))).astype(int)\n",
    "# добавим предсказания некорректных вопросов\n",
    "preds[preds_bin == 1] = -1\n",
    "print(accuracy_score(y_test, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_test.iloc[preds==y_test]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
